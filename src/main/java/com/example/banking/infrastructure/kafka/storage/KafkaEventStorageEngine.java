package com.example.banking.infrastructure.kafka.storage;

import com.example.banking.infrastructure.kafka.bus.KafkaEventBus;
import com.example.banking.infrastructure.lock.DistributedLockService;
import lombok.extern.slf4j.Slf4j;
import org.axonframework.common.jpa.EntityManagerProvider;
import org.axonframework.common.transaction.TransactionManager;
import org.axonframework.eventhandling.DomainEventData;
import org.axonframework.eventhandling.DomainEventMessage;
import org.axonframework.eventhandling.EventMessage;
import org.axonframework.eventsourcing.eventstore.jpa.JpaEventStorageEngine;
import org.axonframework.serialization.Serializer;

import java.util.List;
import java.util.concurrent.TimeUnit;
import java.util.stream.Stream;

/**
 * EventStorageEngine h√≠brido mejorado:
 * 
 * ESCRITURA (appendEvents):
 * ‚úÖ Kafka √öNICAMENTE (source of truth, r√°pido, durabilidad garantizada)
 * ‚úÖ PostgreSQL materializado AS√çNCRONAMENTE por consumer separado
 * 
 * LECTURA (readEventData):
 * ‚úÖ PostgreSQL primero (cache, performance)
 * ‚úÖ Si no existe, trigger materializaci√≥n as√≠ncrona y leer desde Kafka
 * ‚úÖ Lock distribuido para evitar materializaci√≥n concurrente
 * 
 * Ventajas:
 * - Comandos r√°pidos (solo escriben a Kafka)
 * - PostgreSQL puede reconstruirse completamente desde Kafka
 * - Tolerante a fallos de PostgreSQL
 */
@Slf4j
public class KafkaEventStorageEngine extends JpaEventStorageEngine {

    private final KafkaEventBus kafkaEventBus;
    private final EventStoreMaterializer materializer;
    private final DistributedLockService lockService;

    protected KafkaEventStorageEngine(Builder builder) {
        super(builder);
        this.kafkaEventBus = builder.kafkaEventBus;
        this.materializer = builder.materializer;
        this.lockService = builder.lockService;
    }

    /**
     * ‚úÖ MEJORADO: Publica SOLO a Kafka (source of truth)
     * 
     * PostgreSQL se materializa as√≠ncronamente por EventMaterializationConsumer.
     * Esto hace que los comandos sean ultrarr√°pidos.
     */
    @Override
    protected void appendEvents(List<? extends EventMessage<?>> events, Serializer serializer) {
        log.debug("üìù Persistiendo {} eventos - Kafka √öNICAMENTE (source of truth)", events.size());
        
        // Publicar a Kafka (CR√çTICO: Si falla, el comando debe fallar)
        events.stream()
            .filter(event -> event instanceof DomainEventMessage)
            .map(event -> (DomainEventMessage<?>) event)
            .forEach(event -> {
                try {
                    kafkaEventBus.publish(event);
                    log.debug("‚úÖ Evento publicado en Kafka: {} seq={}", 
                        event.getAggregateIdentifier(), event.getSequenceNumber());
                } catch (Exception e) {
                    log.error("üí• CR√çTICO: Error publicando evento a Kafka", e);
                    throw new RuntimeException("No se pudo persistir en Kafka (source of truth)", e);
                }
            });
        
        // NO llamar a super.appendEvents() aqu√≠
        // PostgreSQL se materializa as√≠ncronamente por EventMaterializationConsumer
        
        log.info("‚úÖ {} eventos publicados exitosamente a Kafka (source of truth)", events.size());
    }

    /**
     * ‚úÖ MEJORADO: Lee desde PG si existe, sino trigger materializaci√≥n as√≠ncrona
     * 
     * Flujo optimizado:
     * 1. Verificar si existe en PG (cache hit = r√°pido)
     * 2. Si no existe, verificar con lock distribuido
     * 3. Materializar desde Kafka con lock (evita duplicaci√≥n)
     * 4. Leer desde PG
     */
    @Override
    protected Stream<? extends DomainEventData<?>> readEventData(
            String aggregateIdentifier, long firstSequenceNumber) {
        
        log.debug("üìñ Leyendo eventos: aggregate={}, desde seq={}", 
            aggregateIdentifier, firstSequenceNumber);
        
        // 1. Intentar leer desde PostgreSQL (cache hit)
        if (materializer.isMaterialized(aggregateIdentifier)) {
            log.debug("‚úÖ Cache hit: Aggregate {} encontrado en PostgreSQL", aggregateIdentifier);
            return super.readEventData(aggregateIdentifier, firstSequenceNumber);
        }
        
        // 2. Cache miss: Materializar desde Kafka con lock distribuido
        log.info("‚ö†Ô∏è Cache miss: Aggregate {} NO en PG - Materializando desde Kafka...", 
            aggregateIdentifier);
        
        String lockKey = "materialize:" + aggregateIdentifier;
        
        try {
            // Intentar adquirir lock (timeout 30s)
            boolean executed = lockService.executeWithLock(
                lockKey, 
                30, 
                TimeUnit.SECONDS,
                () -> {
                    // Verificar nuevamente por si otro thread ya materializ√≥
                    if (!materializer.isMaterialized(aggregateIdentifier)) {
                        log.info("üîÑ Materializando aggregate {} desde Kafka...", aggregateIdentifier);
                        materializer.materializeFromKafka(aggregateIdentifier);
                        log.info("‚úÖ Aggregate {} materializado desde Kafka", aggregateIdentifier);
                    } else {
                        log.debug("‚úÖ Aggregate {} ya fue materializado por otro thread", 
                            aggregateIdentifier);
                    }
                }
            );
            
            if (!executed) {
                log.warn("‚ö†Ô∏è Timeout adquiriendo lock para materializar aggregate {}", 
                    aggregateIdentifier);
                throw new RuntimeException("Timeout materializando aggregate desde Kafka");
            }
            
            // 3. Leer desde PostgreSQL (ahora debe estar materializado)
            return super.readEventData(aggregateIdentifier, firstSequenceNumber);
            
        } catch (Exception e) {
            log.error("üí• Error materializando aggregate desde Kafka", e);
            throw new RuntimeException("No se pudo reconstruir aggregate desde Kafka", e);
        }
    }

    /**
     * Snapshots se guardan solo en PostgreSQL (optimizaci√≥n)
     */
    @Override
    protected void storeSnapshot(DomainEventMessage<?> snapshot, Serializer serializer) {
        log.debug("üì∏ Guardando snapshot: aggregate={}, seq={}", 
            snapshot.getAggregateIdentifier(), snapshot.getSequenceNumber());
        super.storeSnapshot(snapshot, serializer);
    }

    public static Builder builder() {
        return new Builder();
    }

    public static class Builder extends JpaEventStorageEngine.Builder {
        private KafkaEventBus kafkaEventBus;
        private EventStoreMaterializer materializer;
        private DistributedLockService lockService;

        @Override
        public Builder snapshotSerializer(Serializer snapshotSerializer) {
            super.snapshotSerializer(snapshotSerializer);
            return this;
        }

        @Override
        public Builder eventSerializer(Serializer eventSerializer) {
            super.eventSerializer(eventSerializer);
            return this;
        }

        @Override
        public Builder upcasterChain(org.axonframework.serialization.upcasting.event.EventUpcaster upcasterChain) {
            super.upcasterChain(upcasterChain);
            return this;
        }

        @Override
        public Builder persistenceExceptionResolver(
                org.axonframework.common.jdbc.PersistenceExceptionResolver persistenceExceptionResolver) {
            super.persistenceExceptionResolver(persistenceExceptionResolver);
            return this;
        }

        @Override
        public Builder entityManagerProvider(EntityManagerProvider entityManagerProvider) {
            super.entityManagerProvider(entityManagerProvider);
            return this;
        }

        @Override
        public Builder transactionManager(TransactionManager transactionManager) {
            super.transactionManager(transactionManager);
            return this;
        }

        @Override
        public Builder batchSize(int batchSize) {
            super.batchSize(batchSize);
            return this;
        }

        public Builder kafkaEventBus(KafkaEventBus kafkaEventBus) {
            this.kafkaEventBus = kafkaEventBus;
            return this;
        }

        public Builder materializer(EventStoreMaterializer materializer) {
            this.materializer = materializer;
            return this;
        }

        public Builder lockService(DistributedLockService lockService) {
            this.lockService = lockService;
            return this;
        }

        @Override
        public KafkaEventStorageEngine build() {
            if (kafkaEventBus == null) {
                throw new IllegalStateException("KafkaEventBus no puede ser null");
            }
            if (materializer == null) {
                throw new IllegalStateException("EventStoreMaterializer no puede ser null");
            }
            if (lockService == null) {
                throw new IllegalStateException("DistributedLockService no puede ser null");
            }
            return new KafkaEventStorageEngine(this);
        }
    }
}