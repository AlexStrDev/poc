# ============================================
# CONFIGURACIÓN DEL SERVIDOR
# ============================================
server.port=8080

# ============================================
# POSTGRESQL - Event Store Cache
# ============================================
spring.datasource.url=jdbc:postgresql://localhost:5432/banking_event_store
spring.datasource.username=postgres
spring.datasource.password=postgres
spring.datasource.driver-class-name=org.postgresql.Driver

# JPA Configuration
spring.jpa.database-platform=org.hibernate.dialect.PostgreSQLDialect
spring.jpa.hibernate.ddl-auto=update
spring.jpa.show-sql=false
spring.jpa.properties.hibernate.format_sql=true
spring.jpa.properties.hibernate.jdbc.lob.non_contextual_creation=true
spring.jpa.properties.hibernate.jdbc.batch_size=50

# Connection Pool
spring.datasource.hikari.maximum-pool-size=20
spring.datasource.hikari.minimum-idle=5
spring.datasource.hikari.connection-timeout=30000

# ============================================
# KAFKA - Event Bus & Command Bus
# ============================================
spring.kafka.bootstrap-servers=localhost:9092

# ============================================
# KAFKA TOPICS
# ============================================
# Comandos
kafka.command.topic=banking-commands
kafka.command.group-id=banking-command-handlers
kafka.command.consumer.concurrency=3
kafka.command.timeout.seconds=30

# Comandos - Dead Letter Queue
kafka.command.dlq.topic=banking-commands-dlq

# Comandos - Respuestas (Request-Reply Pattern)
kafka.command.reply.topic=banking-command-replies
kafka.command.reply.group-id=banking-command-reply-handlers

# Eventos
kafka.events.topic=banking-events
kafka.events.group-id=banking-event-processors

# Eventos - Materialización Asíncrona
kafka.events.materializer.group-id=banking-event-materializer
kafka.events.materializer.concurrency=5

# Materialización - Configuración
kafka.materializer.timeout.seconds=30

# ============================================
# KAFKA PRODUCER (Comandos y Eventos)
# ============================================
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.acks=all
spring.kafka.producer.retries=3
spring.kafka.producer.properties.enable.idempotence=true
spring.kafka.producer.properties.max.in.flight.requests.per.connection=1
spring.kafka.producer.compression.type=snappy

# ============================================
# KAFKA CONSUMER (Comandos y Eventos)
# ============================================
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=false
spring.kafka.consumer.properties.isolation.level=read_committed
spring.kafka.consumer.max-poll-records=100

# ============================================
# AXON FRAMEWORK
# ============================================
# Deshabilitar Axon Server (usamos Kafka)
axon.axonserver.enabled=false

# ============================================
# LOGGING
# ============================================
logging.level.org.axonframework=INFO
logging.level.com.example.banking=DEBUG
logging.level.org.springframework.kafka=INFO
logging.level.org.apache.kafka=WARN
logging.level.org.hibernate.SQL=DEBUG
logging.level.org.hibernate.type.descriptor.sql.BasicBinder=TRACE

# ============================================
# ACTUATOR (Métricas y Health Checks)
# ============================================
management.endpoints.web.exposure.include=health,metrics,info,prometheus
management.endpoint.health.show-details=always
management.metrics.export.prometheus.enabled=true

# ============================================
# NOTAS IMPORTANTES
# ============================================
# 
# PRODUCCIÓN - Kafka Compacted Topics:
# Para máxima eficiencia, configurar los tópicos de eventos como compacted:
# 
# kafka-configs.sh --bootstrap-server localhost:9092 \
#   --entity-type topics \
#   --entity-name banking-events \
#   --alter --add-config cleanup.policy=compact,min.cleanable.dirty.ratio=0.01
#
# Beneficios:
# - Kafka retiene el último snapshot por aggregateId (key)
# - Materialización es O(n) donde n = eventos únicos del aggregate
# - Reduce drásticamente el tiempo de reconstrucción
#
# PRODUCCIÓN - Redis para Cache Distribuido:
# Reemplazar la implementación in-memory con Redis:
# - spring.redis.host=localhost
# - spring.redis.port=6379
# - CommandDeduplicationService: usar RedisTemplate
# - DistributedLockService: usar RedisLockRegistry
#
# PRODUCCIÓN - Métricas con Micrometer:
# - Agregar micrometer-registry-prometheus
# - Exponer métricas en /actuator/prometheus
# - Integrar con Grafana para visualización